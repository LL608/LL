# Data Visulization 
Followed by Data Reshaping and Preprocessing, we obtained a series of tokenized words. Due to the large amount of data set, it is hard for us to uderstand the underlying trends and patterns. Therefore, the data visulization becomes neccesary. As a part of data visulization, the frequency table and wordclouds are genenarated to tell the story behind the data.   
## 1. Process

### 1.1 Generating Frequency Set 
Firstly, we use dictionary in Python to count the frequencies in the 'final_token' list obtained from data shaping. and increment the counter using loops. 

![Frequency Set](https://user-images.githubusercontent.com/78474798/108610401-3c2cf000-73cd-11eb-80b4-a43736206c4c.png)



### 1.2 Word Clouds
![Word cloud](https://user-images.githubusercontent.com/78474798/108610614-efe2af80-73ce-11eb-8ca0-90aaa5c8efe4.png)


### 1.3 Frequency Table 
![Frequency Table](https://user-images.githubusercontent.com/78474798/108610622-0557d980-73cf-11eb-9b67-0274007e207e.png)

## 2. Results 

![fosun cloud1](https://user-images.githubusercontent.com/78474798/108610639-320bf100-73cf-11eb-8510-4159b0eefa90.png)

![fosun frequency](https://user-images.githubusercontent.com/78474798/108610649-4354fd80-73cf-11eb-92dd-cc84d46c4115.png)

## 3. Problems 


